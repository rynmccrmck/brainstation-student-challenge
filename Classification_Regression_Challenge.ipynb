{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification & Regression Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will be filling in blanks (____) in any any section between \n",
    "\n",
    "**### YOUR CODE HERE**\n",
    "\n",
    "and\n",
    "\n",
    "**### END CODE**\n",
    "\n",
    "The purpose of this excercise is to reaffirm your understanding of the difference in classification and regressions tasks, as well as familiarizing with some of the tools available to carry them out.\n",
    "\n",
    "You should refrain from altering the code outside of the designated areas, or create duplicate for exploration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages required\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The two models to be used in this excercise (keep note of the variable names)\n",
    "linear_regression = LinearRegression()\n",
    "logistic_regression = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model profit as a function of population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profit data: \n",
    "# population,profit\n",
    "filename = 'data/profit.csv'\n",
    "\n",
    "### YOUR CODE HERE\n",
    "data = np.loadtxt(fname=____, delimiter=____) # fill in the fname and delimiter arguments\n",
    "### END CODE\n",
    "\n",
    "X, y = np.hsplit(data, 2) # Separate features (x) from target (y)\n",
    "print(X[1],y[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:** \n",
    "\n",
    "\\[ 5.5277\\] \\[ 9.1302\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "plt.plot(X, y, 'bx', label='Data')\n",
    "plt.xlabel('Population')\n",
    "plt.ylabel('Profit')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of training examples\n",
    "\n",
    "## YOUR CODE HERE\n",
    "m = ____\n",
    "print(m)\n",
    "## END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Expected output:** \n",
    " \n",
    " 97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the correct model and fit\n",
    "## YOUR CODE HERE\n",
    "model = ____           # need to select the appropriate model (model_a or model_b)\n",
    "model.fit(____, ____)  # Need to pass the correct arguments to the fit() method\n",
    "## END CODE\n",
    "\n",
    "# Obtain coefficients theta0 and theta1 from model\n",
    "theta0, theta1 = model.intercept_, model.coef_[0]\n",
    "print(theta0,theta1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**:\n",
    "\n",
    "\\[-3.89578088\\] \\[1.19303364\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data with trained regression line\n",
    "plt.plot(X, y, 'bx', label='Data')\n",
    "plt.plot(X, model.predict(X), 'r-', label='Regression')\n",
    "plt.xlabel('Population')\n",
    "plt.ylabel('Profit')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model college admission as a function of two exam scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Admission data: \n",
    "# exam_score_1,exam_score_1,admission\n",
    "filename = 'data/acceptance.csv'\n",
    "data = np.loadtxt(filename, delimiter=',')\n",
    "# Separate features (x1, x2) from target (y)\n",
    "X, y = np.hsplit(data, np.array([2]))\n",
    "y = y.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot data\n",
    "y_pos = y == 1\n",
    "y_neg = y == 0\n",
    "ax.plot(X[y_pos,0], X[y_pos,1], 'g+', label='Admitted')\n",
    "ax.plot(X[y_neg,0], X[y_neg,1], 'ro', label='Not admitted')\n",
    "ax.set_xlabel('Exam 1 score')\n",
    "ax.set_ylabel('Exam 2 score')\n",
    "ax.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the correct model\n",
    "### YOUR CODE HERE \n",
    "model_b = ____\n",
    "model_b.fit(____,____)\n",
    "### END\n",
    "\n",
    "#Obtain coefficients theta0, theta1, theta2\n",
    "theta0 = model_b.intercept_[0]\n",
    "theta1 = model_b.coef_[0,0]\n",
    "theta2 = model_b.coef_[0,1]\n",
    "print(theta0, theta1, theta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "\n",
    "\\[-3.8997779447047662 0.038444815554882487 0.031018545562908596 \\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes x2 at y=0.5 from x1 and model parameters\n",
    "def x2(x1):\n",
    "    return (0.5 - theta0 - theta1*x1) / theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_min = X[:,0].min()\n",
    "x1_max = X[:,0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 and x2 data of linear decision boundary\n",
    "x1_plot = np.array([x1_min, x1_max])\n",
    "x2_plot = x2(x1_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot examples and decision boundary\n",
    "y_pos = y == 1\n",
    "y_neg = y == 0\n",
    "ax.plot(X[y_pos,0], X[y_pos,1], 'g+', label='Admitted')\n",
    "ax.plot(X[y_neg,0], X[y_neg,1], 'ro', label='Not admitted')\n",
    "ax.set_xlabel('Exam 1 score')\n",
    "ax.set_ylabel('Exam 2 score')\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "# Plot decision boundary\n",
    "ax.plot(x1_plot, x2_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider any issues with how we've trained the model:\n",
    "- Can we trust that it will extrapolate to new data well?\n",
    "- Are there ways we can check this?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
